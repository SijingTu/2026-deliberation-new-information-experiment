
\section{Sequential deliberation with new information coming in}
We consider a set of $n$ agents, denoted by $N$, indexed by $u \in [n]$. 
Consider a set of $m$ alternatives, denoted by $M$, indexed by $i \in [m]$. 
Now, we consider each agent has a bliss point in the set of alternatives, denoted by $a^*_u \in M$. 
The bliss point is not involved in the deliberation process, instead, we assume that the agent may uses another stance. 
We assume that the agents' stances, bliss points and the alternatives are all in the unit interval, i.e., $a_u^t, a_u^*, o^t \in [0, 1]$.

Suppose at the $t$-th round of the deliberation, the agent $u$ uses the stance $a_u^t \in M$. 
Let $o^t$ be the outcome of the $t$-th round of the deliberation.  
The deliberation process is as follows. 

\begin{enumerate}
    \item Iteration over $t = 1, 2, \ldots, T$:
    \begin{enumerate}
        \item Uniformly randomly selects a pair of agents $i$ and $j$ from $N$. Let $a_i^{t-1}$ and $a_j^{t-1}$ be the stances that the agents $i$ and $j$ use at the $t-1$-th round for deliberation. The outcome of the previous round of deliberation is $o^{t-1}$.
        \item The agents $i$ and $j$ first update their stances to be $a_i^t = a_i^* (1-\lambda) + o^{t-1} \lambda$ and $a_j^t = a_j^* (1-\lambda) + o^{t-1} \lambda$, where $\lambda \in (0, 1)$ is a parameter.
        \item  The outcome of the current round of deliberation is $o^t$ is the result of the Nash bargaining between the agents $i$ and $j$ using the stances $a_i^t$ and $a_j^t$ for deliberation, i.e., $o^t = Median(\{a_i^t, a_j^t, o^{t-1}\})$ in the median graph setting.
    \end{enumerate}
    \item The final outcome is $o^T$. 
\end{enumerate}

In the above setting, we assume that the stance that the agent ultilizes in the bargaining is the outcome of both the agent's true stance (bliss point), the current alternative in the bargaining, and the stance that the agent uses in the previous bargaining. 

\subsection{Analysis}
We can write down the dynamics of the alternative $o^t$ as follows. 
\begin{equation}
    \begin{aligned}
        o^t = Median(\{a_i^t, a_j^t, o^{t-1}\}) = Median(\{a_i^* (1-\lambda) + o^{t-1} \lambda, a_j^* (1-\lambda) + o^{t-1} \lambda, o^{t-1}\}).
    \end{aligned}
\end{equation}

% \sj{In the following content, I follow the guidelines of ChatGPT to derive the results.}

When $n \rightarrow \infty$, and $a_i^*$ and $a_j^*$ are i.i.d. random variables uniformly distributed in $[0, 1]$. 
Let the random variables picked be $U_1$ and $U_2$ respectively, and the outcome be $X_{t}$
We can write down the following equation. 
\begin{equation}
    \begin{aligned}
        X_{t} = Median(\{U_1 (1-\lambda) + X_{t-1} \lambda, U_2 (1-\lambda) + X_{t-1} \lambda, X_{t-1}\}).
    \end{aligned}
\end{equation}

Conditioned on $X_{t} = X_{t-1}= x$, $Y\coloneqq U_1 (1-\lambda) + x \lambda$ and $Z\coloneqq U_2 (1-\lambda) + x \lambda$ are i.i.d. random variables uniformly distributed in $[\lambda x, (1-\lambda) + \lambda x]$. 

For any value $z \in [0, 1]$, we can write down the following equation. 

\begin{align}
    P(Y \leq z) = P(Z \leq z) = 0 \text{ if } z < \lambda x, \\
    P(Y \leq z) = P(Z \leq z) = \frac{z - \lambda x}{1 - \lambda} \text{ if } \lambda x \leq z < (1-\lambda) + \lambda x, \\
    P(Y \leq z) = P(Z \leq z) = 1 \text{ if } z \geq (1-\lambda) + \lambda x.
\end{align}

Following this, we can write down the probabilities that the median is less than or equal to $z$ as follows.  
\begin{align}
    P(x \leq z \mid x) = 0 \text{ if } z < \lambda x, \\
    P(x \leq z \mid x) = \left(\frac{z - \lambda x}{1 - \lambda}\right)^2 \text{ if } \lambda x \leq z < x, \\
    P(x \leq z \mid x) = 1 - \left(1 - \frac{z -  \lambda x}{1 - \lambda}\right)^2 \text{ if } x \leq z < (1-\lambda) + \lambda x, \\
    P(x \leq z \mid x) = 1 \text{ if } (1-\lambda) + \lambda x \leq z.
\end{align}

\textbf{Question:} Is it possible to derive an approximation distribution of the median?

\subsection{discentarization and simulation}
One way to conduct the analysis is through discretization... 

Below, I conducted some simulations with different $\lambda$ values. 
It seems that as $\lambda$ increases, the distribution of the median becomes more concentrated around the mean. 

\begin{figure}[h]
    \centering
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.00.png}
        \caption{(a) $\lambda = 0.00$}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.20.png}
        \caption{(b) $\lambda = 0.20$}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.40.png}
        \caption{(c) $\lambda = 0.40$}
    \end{minipage}\\[1em]
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.60.png}
        \caption{(d) $\lambda = 0.60$}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.80.png}
        \caption{(e) $\lambda = 0.80$}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../simulation/sim/hist_lambda_0.99.png}
        \caption{(f) $\lambda = 0.99$}
    \end{minipage}
    \caption{Histograms of the median for selected $\lambda$ values.}
    \label{fig:hist_lambda}
\end{figure}



\section{On the line graph when the agents do not update their stances}
Let us revist the results of~\cite{fain2017sequential} when the agents do not update their stances and on the line graph. 
The transition rule is as follows. 
We consider there are in total $n$ points on the line, and we use the short-hand notation that $o^{(t)} = i$ if the outcome of the $t$-th round of the deliberation is the $i$-th point on the line. 

We can simply write down the following transition rule. 
\begin{equation}
    \begin{aligned}
        P(o^{(t+1)} \leq k ) = P(o^{(t)} \leq k)\cdot (1 - (1 - \frac{k}{n})^2) + P(o^{(t)} > k)\cdot (\frac{k}{n})^2.
    \end{aligned}
\end{equation}
And we can solve $P(o \leq k)$ by setting $P(o^{(t+1)} \leq k) = P(o^{(t)} \leq k)$ as follows
\begin{align}
    P(o \leq k) = \frac{k^2}{(n-k)^2 + k^2}.
\end{align}

For the sake of reference of more complex setttings, we can also write the complete transition matrix $P$ as follows. 
When $o^{(t)} = q$, 
\begin{equation}
    \begin{aligned}
        &P(o^{(t+1)} = i | o^{(t)} = q) = \frac{i^2 - (i-1)^2}{n^2}, \text{if } i < q, \\
        &P(o^{(t+1)} = q | o^{(t)} = q) = \frac{n^2 - (q-1)^2 - (n-q)^2}{n^2}, \\
        &P(o^{(t+1)} = i | o^{(t)} = q) = \frac{(n-i+1)^2 - (n-i)^2}{n^2}, if i > q, \\
    \end{aligned}
\end{equation}

\subsection{Considering the setting where the agents are in the line graph}
The problem seems to become too complicated. 
The problem becomes hard as the stances keep changing over the iterations, and it is very hard to propose any formulation for this dynamics.  

\iffalse
Recall the embedding of the median graph into a partial hypercube. 
When the graph is a line graph, the embedding rule is simple.
Consider there are in total $n$ points on the line, then the encoding of the $i$-th point is simply $1\ldots10\ldots0$ with $i$ ones and $n-i$ zeros.

We consider a simpler situation that ${a^{(0)}_{u \in N}}$ is already given. 
We further assume that $a_{u, k}$ be the $k$-th bit of the encoding of the point $a_u$.

% Then, we can define the transition rule of the random walk as follows.
We suppose that the fraction of $1$s for the $k$-th bit over all the $a_u^*$ is $f_k$, i.e., $f_k = \frac{1}{n} \sum_{u \in N} a_{u, k}^*$.
We further suppose that the fraction of $1$s for the $k$-th bit over all the $a_u^{0}$ is $g_k$, i.e., $g_k = \frac{1}{n} \sum_{u \in N} a_{u, k}^{0}$.

Next, suppose we uniformly randomly select a pair of agent $u$ and $v$ from $N$.
It holds that for $u$,

\begin{equation}
    \begin{aligned}
        &P(a_{u, k}^{t+1} = 1 | a_{u, k}^{t} = 1, o_{k}^{t} = 1) = 1, \\
        &P(a_{u, k}^{t+1} = 1 | a_{u, k}^{t} = 1, o_{k}^{t} = 0) = f_{k}, \\
        &P(a_{u, k}^{t+1} = 1 | a_{u, k}^{t} = 0, o_{k}^{t} = 1) = 1 - f_{k}, \\
        &P(a_{u, k}^{t+1} = 1 | a_{u, k}^{t} = 0, o_{k}^{t} = 0) = 0. \\
    \end{aligned}
\end{equation}

And for $v$,

\begin{equation}
    \begin{aligned}
        &P(a_{v, k}^{t+1} = 1 | a_{v, k}^{t} = 1, o_{k}^{t} = 1) = 1, \\
        &P(a_{v, k}^{t+1} = 1 | a_{v, k}^{t} = 1, o_{k}^{t} = 0) = f_{k}, \\
        &P(a_{v, k}^{t+1} = 1 | a_{v, k}^{t} = 0, o_{k}^{t} = 1) = 1 - f_{k}, \\
        &P(a_{v, k}^{t+1} = 1 | a_{v, k}^{t} = 0, o_{k}^{t} = 0) = 0. \\
    \end{aligned}
\end{equation}

and for the outcome $o_k^{t+1}$,

\begin{equation}
    \begin{aligned}
        &P(o_{k}^{t+1} = 1 | a_{u, k}^{t} = 1, a_{v, k}^{t} = 1, o_{k}^{t} = 1) = 1, \\
        &P(o_{k}^{t+1} = 1 | a_{u, k}^{t} = 1, a_{v, k}^{t} = 1, o_{k}^{t} = 0) = f_{k}, \\
        &P(o_{k}^{t+1} = 1 | a_{u, k}^{t} = 0, a_{v, k}^{t} = 1, o_{k}^{t} = 1) = 1 - f_{k}, \\
        &P(o_{k}^{t+1} = 1 | a_{u, k}^{t} = 0, a_{v, k}^{t} = 1, o_{k}^{t} = 0) = 0. \\
    \end{aligned}
\end{equation}
\fi 

\section{Research questions}

\begin{itemize}
    \item Can we define the transition matrix of the random walk defined in the following way?
    \item Can we define the stationary distribution of the process?
    \item Can we compute the distortion guarantee of the process?
\end{itemize}